{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following demonstrate some of the situations in which you would want to use superintendent. Choose an example, and if you're finding you'd like to do more - read the [documentation](http://www.janfreyberg.com/superintendent/).\n",
    "\n",
    "1. [Use case 1: Labelling individual data points](#Use-case-1:-Labelling-individual-data-points)\n",
    "2. [Use case 2: Labelling clusters](#Use-case-2:-Labelling-clusters)\n",
    "3. [Use case 3: Labelling images](#Use-case-3:-labelling-images)\n",
    "4. [Use case 4: Active learning](#Use-case-4:-Active-learning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 1: Labelling individual data points\n",
    "\n",
    "Let's assume we have a text dataset that contains some labelled sentences and some unlabelled sentences. For example, we could get the headlines for a bunch of UK news websites (the code for this comes from the amazing github project [compare-headlines](https://github.com/isobelweinberg/compare-headlines/blob/master/scrape-headlines.ipynb) by [isobelweinberg](https://github.com/isobelweinberg)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "\n",
    "headlines = []\n",
    "labels = []\n",
    "\n",
    "r = requests.get('https://www.theguardian.com/uk').text #get html\n",
    "soup = BeautifulSoup(r, 'html5lib') #run html through beautiful soup\n",
    "headlines += [headline.text for headline in\n",
    "              soup.find_all('span', class_='js-headline-text')][:10]\n",
    "labels += ['guardian'] * (len(headlines) - len(labels))\n",
    "\n",
    "soup = BeautifulSoup(requests.get('http://www.dailymail.co.uk/home/index.html').text, 'html5lib')\n",
    "headlines += [headline.text.replace('\\n', '').replace('\\xa0', '').strip()\n",
    "              for headline in soup.find_all(class_=\"linkro-darkred\")][:10]\n",
    "labels += ['daily mail'] * (len(headlines) - len(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's assume that instead of wanting to know about the source of the article, we actually want to know about how professional the headline is. But we don't have labels for the two! We can use `superintendent` to start creating some. To make sure it's nice and easy on the eyes, we'll also use a custom display function to make the text readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from superintendent import SemiSupervisor\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "\n",
    "labelling_widget = SemiSupervisor(\n",
    "    headlines,\n",
    "    options=['professional', 'not professional'],\n",
    ")\n",
    "\n",
    "labelling_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the new labels that we have created, check the `new_labels` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelling_widget.new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 2: Labelling clusters\n",
    "\n",
    "Another common task is labelling clusters of points. Let's say, for example, that we've k-means-clustered the above data and assigned one of 3 cluster labels to each of the above headlines (we will assign random labels for now):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from superintendent import ClusterSupervisor\n",
    "import numpy as np\n",
    "\n",
    "cluster_labels = np.random.choice([1, 2, 3], size=len(headlines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, rathern than getting one string each time, the display function will receive a list of strings instead, so we should adapt it slightly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c905b20452e5487cb5517dd0cfaf96cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FloatProgress(value=0.0, description='Progress:', max=1.0),)), Box(children=(Out…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labelling_widget = ClusterSupervisor(\n",
    "    headlines,\n",
    "    cluster_labels,\n",
    "    display_func=lambda txt: display.display(display.HTML(\"<br>&nbsp;<br>\".join(txt)))\n",
    ")\n",
    "\n",
    "labelling_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can get the labels for each data point from the object itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test 1',\n",
       " 'test 1',\n",
       " 'test 1',\n",
       " 'test 1',\n",
       " 'test 1',\n",
       " 'test 2',\n",
       " 'test 2',\n",
       " 'test 2',\n",
       " 'test 2',\n",
       " 'test 2',\n",
       " 'test 2',\n",
       " 'test 2',\n",
       " 'test 2',\n",
       " 'test 3',\n",
       " 'test 3',\n",
       " 'test 3',\n",
       " 'test 3',\n",
       " 'test 3',\n",
       " 'test 3',\n",
       " 'test 3']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelling_widget.new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the `cluster index` → `cluster label` mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 'test 1', 1: 'test 2', 3: 'test 3'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelling_widget.new_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, often when we label text clusters, we probably want to not look at all the text individually, but instead want to look at a wordcloud. We can do this by passing a word-cloud generating function to our labeller. We'll use one from the [word_cloud](https://github.com/amueller/word_cloud) package. We'll need to write a little wrapper around it to actually display it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import IPython.display\n",
    "\n",
    "def show_wordcloud(text, n_samples=None):\n",
    "    text = ' '.join(text)\n",
    "    IPython.display.display(\n",
    "        WordCloud().generate(text).to_image()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling_widget = ClusterSupervisor(\n",
    "    headlines, np.random.choice([1, 2, 3], size=len(headlines)),\n",
    "    display_func = show_wordcloud\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82e2a7a621a495e850244f258b063e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FloatProgress(value=0.0, description='Progress:', max=1.0),)), Box(children=(Out…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labelling_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'no',\n",
       " 'no']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelling_widget.new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 3: labelling images\n",
    "\n",
    "For labelling images, there is a special factory method that sets the right display functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from superintendent import SemiSupervisor\n",
    "import numpy as np\n",
    "\n",
    "digits = load_digits().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a255dd7852614da4b9ec2dbaaea78968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FloatProgress(value=0.0, description='Progress:', max=1.0),)), Box(children=(Out…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widget = SemiSupervisor.from_images(\n",
    "    digits[:10, :], options=range(10)\n",
    ")\n",
    "\n",
    "widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 4: Active learning\n",
    "\n",
    "Often, we have a rough idea of an algorithm that might do well on a given task, even if we don't have any labels at all. For example, I know that for a simple image set like MNIST, logistic regression actually does surprisingly well.\n",
    "\n",
    "In this case, we want to do two things:\n",
    "1. We want to keep track of our algorithm's performance\n",
    "2. We want to leverage our algorithm's predictions to decide what data point to label.\n",
    "\n",
    "Both of these things can be done with superintendent. For point one, all we need to do is pass an object that conforms to the fit / predict syntax of sklearn as the `classifier` keyword argument.\n",
    "\n",
    "For the second point, we can choose any function that takes in probabilities of labels (in shape `n_samples, n_classes`), sorts them, and returns the sorted integer index from most in need of labelling to least in need of labelling. Superintendent provides some functions, described in the `superintendent.prioritisation` submodule, that can achieve this. One of these is the `entropy` function, which calculates the entropy of predicted probabilities and prioritises high-entropy samples.\n",
    "\n",
    "As an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58249e439b9f47eeabc6f34ab447850f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HBox(children=(FloatProgress(value=0.0, description='Progress:', max=1.0),), lay…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janfreyberg/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/janfreyberg/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_digits\n",
    "from superintendent import SemiSupervisor\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "data_labeller = SemiSupervisor.from_images(\n",
    "    digits.data[:500, :],\n",
    "    classifier=LogisticRegression(),\n",
    "    options=range(10),\n",
    "    reorder='entropy',\n",
    ")\n",
    "\n",
    "data_labeller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 5: Distributed labelling\n",
    "\n",
    "If you would like to distribute your labelling over a team of labellers, you can do so with the `superintendent.distributed` submodule. It uses a database to manage the task across lots of people: the tests and default implementation run with sqlite, but it's recommended that you use e.g. PostgreSQL if you do this with lots of people for improved stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59026bde92a64cda8b0b0691827858e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Please enter your name:</h2>'), Box(children=(Text(value='', placeholder='Pleas…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_digits\n",
    "from superintendent.distributed import SemiSupervisor\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "# clear up any previous testing database\n",
    "!rm /tmp/test.db;\n",
    "\n",
    "data_labeller = SemiSupervisor.from_images(\n",
    "    connection_string=\"sqlite:////tmp/test.db\",\n",
    "    features=digits.data[:500, :],\n",
    "    worker_id=True,\n",
    "    table_name='superintendent_examples',\n",
    ")\n",
    "\n",
    "data_labeller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can achieve active learning by using the \"orchestrate\" method of an active learning widget. This method simply runs in a forever-while loop, continually retraining the model and reassigning priorities for data points based on the algorithm's output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_digits\n",
    "from superintendent.distributed import SemiSupervisor\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "# clear up any previous testing database\n",
    "!rm /tmp/test.db;\n",
    "\n",
    "data_labeller = SemiSupervisor.from_images(\n",
    "    connection_string=\"sqlite:////tmp/test.db\",\n",
    "    features=digits.data[:500, :],\n",
    "    classifier=LogisticRegression(),\n",
    "    table_name='superintendent_examples',\n",
    ")\n",
    "\n",
    "data_labeller.orchestrate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
